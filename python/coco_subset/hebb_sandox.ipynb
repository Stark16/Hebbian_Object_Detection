{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jknize/main/repo/CSC578/detectron2')\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "register_coco_instances(\"coco_train_dog\", {}, \"../datasets/coco/annotations/dog_instances_train2017.json\", \"../datasets/coco/train2017_dog\")\n",
    "register_coco_instances(\"coco_val_dog\", {}, \"../datasets/coco/annotations/dog_instances_val2017.json\", \"../datasets/coco/val2017_dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/17 11:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 4385 images in COCO format from ../datasets/coco/annotations/dog_instances_train2017.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "my_dataset_metadata = MetadataCatalog.get(\"coco_train_dog\")\n",
    "my_dataset_metadata.thing_classes = [\"dog\"]\n",
    "dataset_dicts = DatasetCatalog.get(\"coco_train_dog\")\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "import torch\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"configs/COCO-Detection/hebb_knize0.yaml\")\n",
    "cfg.OUTPUT_DIR = \"knize/output/hebb_sandbox\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"coco_train_dog\",)\n",
    "cfg.DATASETS.TEST = (\"coco_val_dog\",)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.OUTPUT_LAYER_SIZE = 1\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "cfg.SOLVER.BASE_LR = 0.0025\n",
    "cfg.SOLVER.MAX_ITER = 5\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "\n",
    "# set each image to 224x224 for dev purposes. we will want to change this later to improve performance\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (64,)\n",
    "cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 64\n",
    "cfg.INPUT.MIN_SIZE_TEST = 64\n",
    "cfg.INPUT.MAX_SIZE_TEST = 64\n",
    "# cfg.PROPOSAL_GENERATOR: PrecomputedProposals # this may be an option to potentially avoid issues with proposal generation\n",
    "# TODO: think about image normalization \"cfg.PIXEL_MEAN\"\n",
    "cfg.MODEL.ROI_HEADS.IN_FEATURES: ['res4']\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NAME = \"StandardROIHeads\"\n",
    "cfg.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n",
    "cfg.MODEL.ROI_BOX_HEAD.FC_DIM = 32\n",
    "cfg.MODEL.ROI_BOX_HEAD.CONV_DIM = 8\n",
    "# TODO i'm not sure how to set these two up below (pave)\n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_CONV = 2\n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_FC = 2\n",
    "\n",
    "# run on GPU\n",
    "cfg.MODEL.DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/17 11:12:09 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): HebbNet(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (hebbian_weights): Linear(in_features=12288, out_features=131072, bias=False)\n",
      "    (classification_weights): Linear(in_features=131072, out_features=1, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (softmax): LogSoftmax(dim=1)\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (conv1): Conv2d(\n",
      "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=1568, out_features=32, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=32, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=32, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[11/17 11:12:09 d2.data.datasets.coco]: \u001b[0mLoaded 4385 images in COCO format from ../datasets/coco/annotations/dog_instances_train2017.json\n",
      "\u001b[32m[11/17 11:12:09 d2.data.build]: \u001b[0mLoading proposals from: detectron2://COCO-Detection/rpn_R_50_FPN_1x/137258492/coco_2017_train_box_proposals_21bc3a.pkl\n",
      "\u001b[32m[11/17 11:12:13 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4385 images left.\n",
      "\u001b[32m[11/17 11:12:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(64,), max_size=64, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[11/17 11:12:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/17 11:12:13 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[11/17 11:12:13 d2.data.common]: \u001b[0mSerializing 4385 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/17 11:12:13 d2.data.common]: \u001b[0mSerialized dataset takes 119.68 MiB\n",
      "\u001b[32m[11/17 11:12:13 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/17 11:12:13 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[11/17 11:12:13 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[11/17 11:12:13 d2.data.datasets.coco]: \u001b[0mLoaded 177 images in COCO format from ../datasets/coco/annotations/dog_instances_val2017.json\n",
      "\u001b[32m[11/17 11:12:13 d2.data.build]: \u001b[0mLoading proposals from: detectron2://COCO-Detection/rpn_R_50_FPN_1x/137258492/coco_2017_val_box_proposals_ee0dad.pkl\n",
      "\u001b[32m[11/17 11:12:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(64, 64), max_size=64, sample_style='choice')]\n",
      "\u001b[32m[11/17 11:12:13 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[11/17 11:12:13 d2.data.common]: \u001b[0mSerializing 177 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/17 11:12:13 d2.data.common]: \u001b[0mSerialized dataset takes 4.80 MiB\n",
      "\u001b[32m[11/17 11:12:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 177 batches\n",
      "\u001b[32m[11/17 11:12:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/177. Dataloading: 0.0010 s/iter. Inference: 0.0143 s/iter. Eval: 0.0002 s/iter. Total: 0.0154 s/iter. ETA=0:00:02\n",
      "\u001b[32m[11/17 11:12:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.861207 (0.022449 s / iter per device, on 1 devices)\n",
      "\u001b[32m[11/17 11:12:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.018704 s / iter per device, on 1 devices)\n",
      "\u001b[32m[11/17 11:12:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/17 11:12:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./knize/output/hebb_sandbox/coco_instances_results.json\n",
      "\u001b[32m[11/17 11:12:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.049\n",
      "\u001b[32m[11/17 11:12:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.064 | 0.328  | 0.004  | 0.000 | 0.057 | 0.115 |\n",
      "OrderedDict([('bbox', {'AP': 0.06405795435207037, 'AP50': 0.32754295007908435, 'AP75': 0.004125412541254125, 'APs': 0.0, 'APm': 0.057060899737083025, 'APl': 0.1154156918289138})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# evaluate performance of trained subset model\n",
    "cfg.MODEL.WEIGHTS = \"./knize/output/dog_ROI_HEAD_tinkering/model_final.pth\"\n",
    "\n",
    "# trainer.model.eval()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "\n",
    "evaluator = COCOEvaluator(\"coco_val_dog\", (\"bbox\",), False, output_dir=\"./knize/output/hebb_sandbox\")\n",
    "val_loader = build_detection_test_loader(cfg, \"coco_val_dog\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
    "\n",
    "## I don't know why the score doesn't evaluate correctly when loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/17 11:15:16 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./knize/output/dog_ROI_HEAD_tinkering/model_final.pth ...\n",
      "\u001b[32m[11/17 11:15:22 d2.data.datasets.coco]: \u001b[0mLoaded 177 images in COCO format from ../datasets/coco/annotations/dog_instances_val2017.json\n"
     ]
    }
   ],
   "source": [
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"coco_val_dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset_dicts[:]:\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    \n",
    "    # Get model predictions\n",
    "    try:\n",
    "        outputs = predictor(img)\n",
    "        # Visualize the predictions\n",
    "        v = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"coco_val_dog\"), scale=0.5)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "        # Plot the image\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    except:\n",
    "        \"No proposal\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
